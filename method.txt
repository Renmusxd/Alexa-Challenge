The state of affairs in applying neural networks (NNâ€™s) to natural language processing (NLP), particularly in the realm of conversational nets and social or chat bots is rapidly evolving. Today, proposed architectures limit their scope to only a neural network architecture, and do not focus on integration across broad aspects of the NLP AI research space. Each proposal attempts to utilize one solution for the entire problem at hand. Few proposals have brought multiple architectures together in a way that can provide new, robust response and behavior. Additionally, very little is "hard coded" in these architectures, but hard coded patches can potentially hide some of the imperfections in neural network architectures. Our goal is to bring several state-of-the-art NN designs together to achieve more coherent, deeper conversations. 

Since we do not know a priori how these architectures will interact with each other, we must develop a methodology to test various iterations of architecture designs. Below we will discuss possible methodologies for determining good architectures that interface with each other. Additionally we will discuss different designs under consideration and how they fit into the architecture provided in our design document.

For each of the modules included in the design document we plan to look into similar alternatives. For example DMNs could be replaced with alternative database queries, or LSTMs could be replaced with TACNTNs (Yu Wu et al. https://arxiv.org/abs/1605.00090). Each of these modules would be trained on equivalent data and incorporated into the overall design. The training of these modules is accomplished using reinforcement learning as proposed in Dan Jurafsky's paper Deep Reinforcement Learning for Dialogue Generation (Dan Jurafsky et al. https://arxiv.org/abs/1606.01541).

Similar architectures and module options can also be chosen between if their response accuracy is similar. Their accuracy may be dependent on the type of input phrases, thus keeping both architectures would be worthwhile with a specially trained classifier sending inputs into either option. We would train the classifier to maximize overall accuracy of inputs by selecting one of the options. This input distpatch design could be kept in the final architecture or used solely to analyse weaknesses of each module to further refine training. This methodology can be applied at every step of our design when trying out the various low-level implementations outlined in the next section of this document.

Current examples of these architecture choices in the DD section include topic classifications. Topic classification of text has a rich history from SVMs, LDAs, and even CNNs. Each of these has strengths and weaknesses for different styles of phrases as well as their ability to infer and work around rare word usage. Choosing between classifiers would require experimentation on the specific phrases used in conversation rather than in written text. Should ambiguities arise we can fall back on the topic database confidence to determine which of the topics most accurately represents and responds to the query.

The topics themselves have multiple options. Though DMNs offer many benefits we should allow the model to operate independent of the choice of database at the level of the CC to DD connection as well as within the DD module itself. Topic classification should dispatch the query to the relevant topic(s), we can then rate which choice of topic is most suited by comparing the generated output to articles in the field. For example a question about the age of a movie star can be compared to phrases in that star's wikipedia page to gauge accuracy. As such the query "I keep hearing about [TOPIC], what is that?" should return an answer similar to some information available in the wikipedia article. Training should reflect this by comparing results from the socialbot to phrases available in the wikipedia article (wikipedia here is an example of one potential database, as the scale of the project grows we would, of course, build a custom database from freely available information to optimize this information retrieval as an english language version of Freebase).